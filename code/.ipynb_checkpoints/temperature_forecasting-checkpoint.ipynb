{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Temperature Anomaly: Time Series Modeling\n",
    "#### Lucas Dwyer\n",
    "##### https://github.com/AuraSinis/global_temperature_anomaly_forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement:\n",
    "##### The potential impacts of climate change affect many facets of our everyday lives.\n",
    "##### One important metric one can use to keep track of exactly how severely the climate has changed is the Global Temperature Anomaly (GTA), which is the rise in the global average temperature over the past few decades.\n",
    "##### Forecasting the GTA years in advance is necessary in order to give prompt insight to policy makers regarding timetables for green climate policy changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import autocorrelation_plot, register_matplotlib_converters\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression,Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "%matplotlib inline\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    y_train_hat = model.predict(X)\n",
    "    # give me the r2, mse, and rmse for our training split\n",
    "    print(f'R2 Score: {r2_score(y, y_train_hat)}')\n",
    "    print(f'MSE: {mean_squared_error(y, y_train_hat)}')\n",
    "    print(f'RMSE: {mean_squared_error(y, y_train_hat)**0.5}')\n",
    "    \n",
    "def heatmap(df,m,n, drop=[]):\n",
    "    plt.figure(figsize = (n,m))\n",
    "\n",
    "    # get correlation of variables\n",
    "\n",
    "    corr = df.drop(columns=drop,axis=1).corr()\n",
    "\n",
    "    # get rid of top right triangle half\n",
    "    mask = np.zeros_like(corr)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    # plot heatmap\n",
    "    with sns.axes_style(\"white\"):\n",
    "        sns.heatmap(corr, mask = mask, square = True, annot = True, vmin = -1, vmax = 1, linewidths = .5)\n",
    "        \n",
    "def interpret_dftest(dftest):\n",
    "    dfoutput = pd.Series(dftest[0:2], index=['Test Statistic','p-value'])\n",
    "    return dfoutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read, Clean, Transform Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Global Temperature Anomalies Dataset (NOAA)](https://www.ncdc.noaa.gov/cag/global/time-series/globe/land_ocean/ytd/12/1880-2020/data.csv)<br>\n",
    "[World Methane Emissions Dataset (World Bank)](http://api.worldbank.org/v2/en/indicator/EN.ATM.METH.KT.CE?downloadformat=csv)<br>\n",
    "[Global Annual Carbon ppm Historical Dataset (IAC)](ftp://data.iac.ethz.ch/CMIP6/input4MIPs/UoM/GHGConc/CMIP/yr/atmos/UoM-CMIP-1-1-0/GHGConc/gr3-GMNHSH/v20160701/mole_fraction_of_carbon_dioxide_in_air_input4MIPs_GHGConcentrations_CMIP_UoM-CMIP-1-1-0_gr3-GMNHSH_0000-2014.csv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_mole_carbon = pd.read_csv('../data/co2/mole_fraction_of_carbon_dioxide_in_air_input4MIPs_GHGConcentrations_CMIP_UoM-CMIP-1-1-0_gr3-GMNHSH_0000-2014.csv')\n",
    "world = pd.read_csv('../data/meteorological/world.csv',index_col=0)\n",
    "methane = pd.read_csv('../data/methane/adjusted.csv',index_col=0)\n",
    "year_mole_carbon = year_mole_carbon[year_mole_carbon['year']>=1970]\n",
    "world = world.iloc[4:]\n",
    "world.index= pd.to_datetime(world.index)\n",
    "year_mole_carbon.index= pd.to_datetime(year_mole_carbon.year,format=\"%Y\")\n",
    "world['January-December'] = world[' January-December'].astype('float64')\n",
    "world = world.drop(labels = ' January-December', axis =1)\n",
    "na_years = [\n",
    "    'Indicator Code',\n",
    "    'Indicator Name',\n",
    "    'Country Code',\n",
    "    '1960',\n",
    "    '1961',\n",
    "    '1962',\n",
    "    '1963',\n",
    "    '1964',\n",
    "    '1965',\n",
    "    '1966',\n",
    "    '1967',\n",
    "    '1968',\n",
    "    '1969',\n",
    "    '2013',\n",
    "    '2014',\n",
    "    '2015',\n",
    "    '2016',\n",
    "    '2017',\n",
    "    '2018',\n",
    "    '2019',]\n",
    "methane = methane.drop(na_years, axis=1)\n",
    "methane_trans = methane.transpose()\n",
    "world.index = world.index.strftime('%Y')\n",
    "methane_w = methane_trans['World'].dropna()\n",
    "methane_w.index = pd.to_datetime(methane_w.index)\n",
    "aggr = pd.DataFrame(methane_w).join(world.loc[world.index > '1969-10-16 08:00:00'])\n",
    "aggr = aggr.join(year_mole_carbon)\n",
    "aggr= aggr.drop(['data_mean_nh', 'data_mean_sh','year'],axis=1)\n",
    "aggr.columns = ['world_methane', 'temp_anomaly','world_carbon']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect features, feature correlation, and feature differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(aggr,4,4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "year_mole_carbon[year_mole_carbon['data_mean_global']>=300].plot(y='data_mean_global');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = methane_trans['World'].plot();\n",
    "ax.set_title('Methane Emissions (kiloton of CO2 equivalent)');\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('kilotons of CO2 equivalent');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = year_mole_carbon[year_mole_carbon['year']>=1970]['data_mean_global'].plot();\n",
    "ax.set_title('Carbon Levels (ppm)');\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('parts per million');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = world.loc[world.index > '1970-10-16 08:00:00'].plot();\n",
    "ax.get_legend().remove()\n",
    "ax.set_title('Global Average Temperature Anomaly (ºC)');\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Anomaly in ºC');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect 1st and 2nd order differences for stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = aggr['temp_anomaly'].diff(1).plot();\n",
    "ax2 = aggr['temp_anomaly'].diff(1).diff(1).plot(ax=ax1);\n",
    "ax1.legend(labels = ['1st Difference', '2nd Difference'])\n",
    "ax1.set_title('1st & 2nd Differences of Temperature Anomaly');\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('ºC per year, or ºC per $year^2$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1= aggr['world_methane'].diff(1).plot();\n",
    "ax2= aggr['world_methane'].diff(1).diff(1).plot(ax=ax1);\n",
    "ax1.legend(labels = ['1st Difference', '2nd Difference'])\n",
    "ax1.set_title('1st & 2nd Differences of Methane Emissions');\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('kt CO2 eq. per year, or kt CO2 eq. per $year^2$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1= aggr['world_carbon'].diff(1).plot();\n",
    "ax2=aggr['world_carbon'].diff(1).diff(1).plot(ax=ax1);\n",
    "ax1.legend(labels = ['1st Difference', '2nd Difference'])\n",
    "ax1.set_title('1st & 2nd Differences of Carbon levels');\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('ppm per year, or ppm per $year^2$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for stationarity using Augmented Dickey-Fuller tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Temperature Anomaly:')\n",
    "print(interpret_dftest(adfuller(aggr['temp_anomaly'])))\n",
    "print(interpret_dftest(adfuller(aggr['temp_anomaly'].diff(1).dropna())))\n",
    "print(interpret_dftest(adfuller(aggr['temp_anomaly'].diff(1).diff(1).dropna())))\n",
    "print('Methane')\n",
    "print(interpret_dftest(adfuller(aggr['world_methane'])))\n",
    "print(interpret_dftest(adfuller(aggr['world_methane'].diff(1).dropna())))\n",
    "print(interpret_dftest(adfuller(aggr['world_methane'].diff(1).diff(1).dropna())))\n",
    "print('Carbon')\n",
    "print(interpret_dftest(adfuller(aggr['world_carbon'])))\n",
    "print(interpret_dftest(adfuller(aggr['world_carbon'].diff(1).dropna())))\n",
    "print(interpret_dftest(adfuller(aggr['world_carbon'].diff(1).diff(1).dropna())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check auto- & partial auto-correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(aggr['temp_anomaly'],lags = 24);\n",
    "plot_pacf(aggr['temp_anomaly'],lags = 12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(aggr['world_methane'],lags = 24);\n",
    "plot_pacf(aggr['world_methane'],lags = 12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(aggr['world_carbon'],lags = 24);\n",
    "plot_pacf(aggr['world_carbon'],lags = 12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorrelation_plot(aggr['temp_anomaly']);\n",
    "autocorrelation_plot(aggr['world_methane']);\n",
    "autocorrelation_plot(aggr['world_carbon']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr['temp_a_diff_1']= aggr['temp_anomaly'].diff(1)\n",
    "aggr['target'] = aggr['temp_a_diff_1'].shift(-1)\n",
    "aggr['temp_a_diff_2']= aggr['temp_anomaly'].diff(1).diff(1)\n",
    "aggr['world_methane_diff_1']= aggr['world_methane'].diff(1)\n",
    "aggr['world_methane_diff_2']= aggr['world_methane'].diff(1).diff(1)\n",
    "aggr['world_carbon_diff_1']= aggr['world_carbon'].diff(1)\n",
    "aggr['world_carbon_diff_2']= aggr['world_carbon'].diff(1).diff(1)\n",
    "aggr = aggr.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(aggr,15,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(aggr);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['world_methane_diff_2', 'world_carbon_diff_2', 'temp_a_diff_1', ]\n",
    "X= aggr[features]\n",
    "y= aggr['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = Ridge(alpha=9,fit_intercept=False,solver= 'auto')\n",
    "ridge_model.fit(X_train_sc, y_train)\n",
    "\n",
    "print(ridge_model.score(X_train_sc, y_train))\n",
    "evaluate_model(ridge_model, X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ridge_model.predict(X_test_sc)\n",
    "df = pd.DataFrame(y_test)\n",
    "df['pred'] = pred\n",
    "residuals_ridge = (y_test) - pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inspect Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_ridge.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_ridge.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "fig1 = sns.scatterplot(pred, residuals_ridge );\n",
    "fig1.set(xlabel = 'Temperature Anomaly Difference', ylabel= 'Residual', title = 'Residuals Plot');\n",
    "sns.set(font_scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check Temperature Anomaly 1st Difference predictions against real test set values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = df.reset_index().plot(kind='scatter',x='index', y='target', color='r')    \n",
    "ax2 = df.reset_index().plot(kind='scatter',x='index', y='pred', color='g', ax=ax1)\n",
    "ax1.legend(labels = ['Actual', 'Predicted'])\n",
    "ax1.set_title('Actual vs Predicted Temperature Anomaly Differences in ºCelsius per year');\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('Temperature Anomaly difference per year (ºC/year)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_alphas = np.logspace(-3, 0, 100)\n",
    "lasso_cv = LassoCV(alphas=l_alphas, cv=5, max_iter=5000, fit_intercept=False)\n",
    "lasso_cv.fit(X_train_sc, y_train)\n",
    "evaluate_model(lasso_cv, X_test_sc, y_test)\n",
    "pred = lasso_cv.predict(X_test_sc)\n",
    "df['pred'] = pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check Temperature Anomaly 1st Difference predictions against real test set values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = df.reset_index().plot(kind='scatter',x='index', y='target', color='r')    \n",
    "ax2 = df.reset_index().plot(kind='scatter',x='index', y='pred', color='g', ax=ax1)\n",
    "ax1.legend(labels = ['Actual', 'Predicted'])\n",
    "ax1.set_title('Actual vs Predicted Temperature Anomaly Differences in ºCelsius per year');\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('Temperature Anomaly difference per year (ºC/year)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_lasso = (y_test) - pred\n",
    "residuals_lasso.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_lasso.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inspect Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "fig1 = sns.scatterplot(pred, residuals_lasso );\n",
    "fig1.set(xlabel = 'Temperature Anomaly Difference', ylabel= 'Residual', title = 'Residuals Plot');\n",
    "sns.set(font_scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quick Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(lasso_cv, X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(ridge_model, X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statsmodel OLS\n",
    "##### Check Plain Ol' Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)\n",
    "X_train.dropna(inplace=True)\n",
    "y_train = y_train[X_train.index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lm = sm.OLS(y_train, X_train)\n",
    "lm_results = lm.fit()\n",
    "print(lm_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olm_results = lm_results.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(lm_results, X_test,y_test)\n",
    "ols_reg = y_test - lm_results.predict(X_test)\n",
    "ols_reg.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare the sum of the absolute residuals between the OLS and Ridge models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(abs(ols_reg).sum())\n",
    "print(abs(residuals_ridge).sum())\n",
    "print((abs(residuals_ridge).sum()/abs(ols_reg).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reset data, keep unscaled copy for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = aggr\n",
    "df = df[['world_methane_diff_2', 'world_carbon_diff_2', 'temp_a_diff_1', 'target']]\n",
    "ss = StandardScaler()\n",
    "array = ss.fit_transform(df)\n",
    "array = pd.DataFrame(array)\n",
    "array.columns = df.columns\n",
    "array.index = df.index\n",
    "df_train, df_test = train_test_split(df,\n",
    "                                     test_size = 0.25,\n",
    "                                     random_state=42,\n",
    "                                     shuffle = False)\n",
    "train, test = train_test_split(array,\n",
    "                               test_size = 0.25,\n",
    "                               random_state=42,\n",
    "                               shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAR Model + Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAR(train)\n",
    "ts_model = model.fit(maxlags=3, \n",
    "                     ic='aic')\n",
    "print(ts_model.k_ar)\n",
    "ts_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_model.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_model.plot_forecast(12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_model.plot_forecast(3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = ts_model.forecast(train.values, len(test))\n",
    "df_forecast = ss.inverse_transform(forecast)\n",
    "for i in range(test.shape[1]):\n",
    "    print(f'The test MSE on the scaled {test.columns[i]} data is: {round(mean_squared_error(test.values[:, i], forecast[:, i]), 4)}')\n",
    "for i in range(test.shape[1]):\n",
    "    print(f'The test MSE on the unscaled {df_test.columns[i]} data is: {round(mean_squared_error(df_test.values[:, i], df_forecast[:, i]), 4)}')\n",
    "df_forecast = pd.DataFrame(df_forecast)\n",
    "df_forecast.index= df_test.index\n",
    "df_forecast.columns = df_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot Predicted Temperature Anomaly vs Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = aggr.tail(12)\n",
    "check = pd.DataFrame(check['temp_anomaly'])\n",
    "check['temp_a_diff_est'] = df_forecast['temp_a_diff_1']\n",
    "transf = [None]*12\n",
    "transf[2] = 0.62\n",
    "for i in range (3,12):\n",
    "    transf[i] = transf[i-1]+check.iloc[i-1,1]\n",
    "check['pred_temp_anomaly'] = transf\n",
    "check = check.iloc[3:]\n",
    "print(mean_squared_error(check['temp_anomaly'],check['pred_temp_anomaly']))\n",
    "ax3 = check.reset_index().plot(kind='scatter',x='index', y='temp_anomaly', color='r')    \n",
    "ax4 = check.reset_index().plot(kind='scatter',x='index', y='pred_temp_anomaly', color='g', ax=ax3)\n",
    "ax3.legend(labels = ['Actual', 'Predicted'])\n",
    "ax3.set_title('Actual vs Predicted Temperature Anomalies in Celsius');\n",
    "ax3.set_xlabel('Year')\n",
    "ax3.set_ylabel('Temperature Anomaly (ºC)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=42, shuffle=False)\n",
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = Ridge(alpha=8,fit_intercept=False,solver= 'saga')\n",
    "ridge_model.fit(X_train_sc, y_train)\n",
    "pred = ridge_model.predict(X_test_sc)\n",
    "print(ridge_model.score(X_train_sc, y_train))\n",
    "evaluate_model(ridge_model, X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot Predicted Temperature Anomaly vs Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = aggr.tail(12)\n",
    "check = pd.DataFrame(check['temp_anomaly'])\n",
    "hold = [None]*2\n",
    "hold.extend(list(pred))\n",
    "transf = [None]*12\n",
    "transf[2] = 0.62\n",
    "for i in range (3,12):\n",
    "    transf[i] = transf[i-1]+pred[i-3]\n",
    "check['pred_temp_anomaly'] = transf\n",
    "check = check.iloc[2:]\n",
    "print(mean_squared_error(check['temp_anomaly'],check['pred_temp_anomaly']))\n",
    "ax3 = check.reset_index().plot(kind='scatter',x='index', y='temp_anomaly', color='r', figsize= (12,7))    \n",
    "ax4 = check.reset_index().plot(kind='scatter',x='index', y='pred_temp_anomaly', color='g', ax=ax3)\n",
    "ax3.legend(labels = ['Actual', 'Predicted'])\n",
    "ax3.set_title('Actual vs Predicted Temperature Anomalies in Celsius');\n",
    "ax3.set_xlabel('Year')\n",
    "ax3.set_ylabel('Temperature Anomaly (ºC)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Predictions Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_alphas = np.logspace(-3, 0, 100)\n",
    "lasso_cv = LassoCV(alphas=l_alphas, cv=5, max_iter=5000, fit_intercept=False)\n",
    "lasso_cv.fit(X_train_sc, y_train)\n",
    "evaluate_model(lasso_cv, X_test_sc, y_test)\n",
    "pred = lasso_cv.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot Predicted Temperature Anomaly vs Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = aggr.tail(12)\n",
    "check = pd.DataFrame(check['temp_anomaly'])\n",
    "hold = [None]*2\n",
    "hold.extend(list(pred))\n",
    "transf = [None]*12\n",
    "transf[2] = 0.62\n",
    "for i in range (3,12):\n",
    "    transf[i] = transf[i-1]+pred[i-3]\n",
    "check['pred_temp_anomaly'] = transf\n",
    "check = check.iloc[3:]\n",
    "print(mean_squared_error(check['temp_anomaly'],check['pred_temp_anomaly']))\n",
    "ax3 = check.reset_index().plot(kind='scatter',x='index', y='temp_anomaly', color='r', figsize=(12,7))    \n",
    "ax4 = check.reset_index().plot(kind='scatter',x='index', y='pred_temp_anomaly', color='g', ax=ax3) \n",
    "ax3.legend(labels = ['Actual', 'Predicted'])\n",
    "ax3.set_title('Actual vs Predicted Temperature Anomalies in Celsius');\n",
    "ax3.set_xlabel('Year')\n",
    "ax3.set_ylabel('Temperature Anomaly (ºC)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLM Temperature Anomaly Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot Predicted Temperature Anomaly vs Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = aggr.tail(12)\n",
    "check = pd.DataFrame(check['temp_anomaly'])\n",
    "transf = [None]*12\n",
    "transf[2] = 0.62\n",
    "for i in range (3,12):\n",
    "    transf[i] = transf[i-1]+olm_results[i-2]\n",
    "check['pred_temp_anomaly']= transf\n",
    "check = check.dropna()\n",
    "print(mean_squared_error(check['temp_anomaly'],check['pred_temp_anomaly']))\n",
    "ax3 = check.reset_index().plot(kind='scatter',x='index', y='temp_anomaly', color='r')    \n",
    "ax4 = check.reset_index().plot(kind='scatter',x='index', y='pred_temp_anomaly', color='g', ax=ax3)\n",
    "ax1.legend(labels = ['Actual', 'Predicted'])\n",
    "ax1.set_title('Actual vs Predicted Temperature Anomaly Differences in ºCelsius per year');\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('Temperature Anomaly difference per year (ºC/year)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = train_test_split(aggr['target'],\n",
    "                                   random_state=42,\n",
    "                                   shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic ARIMA model time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manuallu check through ARIMA for best fit via loops\n",
    "best_aic = 99 * (10 ** 16)\n",
    "best_p = 0\n",
    "best_q = 0\n",
    "\n",
    "for p in range(5):\n",
    "    for q in range(5):\n",
    "        try:\n",
    "            print(f'Attempting to fit ARIMA({p},0,{q})')\n",
    "            arima = ARIMA(freq='AS-JAN',\n",
    "                          endog = y_train.astype(float).dropna(),\n",
    "                          order = (p,0,q))\n",
    "            model = arima.fit()\n",
    "            print(f'The AIC for ARIMA({p},0,{q}) is: {model.aic}')\n",
    "            if model.aic < best_aic:\n",
    "                best_aic = model.aic\n",
    "                best_p = p\n",
    "                best_q = q\n",
    "        except:\n",
    "            pass\n",
    "print()\n",
    "print()\n",
    "print('MODEL FINISHED!')\n",
    "print(f'Our model that minimizes AIC on the training data is the ARIMA({best_p},0,{best_q}).')\n",
    "print(f'This model has an AIC of {best_aic}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instantiate to best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(endog = y_train.astype(float).dropna(),\n",
    "              order = (0,0,1))\n",
    "\n",
    "arima = model.fit()\n",
    "print(f'This model has an AIC of {arima.aic}.')\n",
    "preds = model.predict(params = arima.params,\n",
    "                      start = y_test.index[0],\n",
    "                      end = y_test.index[-1])\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(y_train.index, pd.DataFrame(y_train), color = 'blue')\n",
    "plt.plot(y_test.index, pd.DataFrame(y_test), color = 'orange')\n",
    "plt.plot(y_test.index, preds, color = 'green')\n",
    "\n",
    "plt.title(label = 'Once-Differenced Global Mean Temperature with ARIMA(0, 1, 3) Predictions', fontsize=16)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test,preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot Predicted Temperature Anomaly vs Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = aggr.tail(12)\n",
    "check = pd.DataFrame(check['temp_anomaly'])\n",
    "transf = [None]*12\n",
    "transf[2] = 0.62\n",
    "for i in range (3,12):\n",
    "    transf[i] = transf[i-1]+preds[i-3]\n",
    "check['pred_temp_anomaly']= transf\n",
    "check = check[2:]\n",
    "print(mean_squared_error(check['temp_anomaly'],check['pred_temp_anomaly']))\n",
    "ax3 = check.reset_index().plot(kind='scatter',x='index', y='temp_anomaly', color='r', figsize=(12,7))    \n",
    "ax4 = check.reset_index().plot(kind='scatter',x='index', y='pred_temp_anomaly', color='g', ax=ax3)\n",
    "ax3.legend(labels = ['Actual', 'Predicted'])\n",
    "ax3.set_title('Actual vs Predicted Temperature Anomalies in Celsius');\n",
    "ax3.set_xlabel('Year')\n",
    "ax3.set_ylabel('Temperature Anomaly (ºC)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA + LASSO/Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['world_methane_diff_2', 'world_carbon_diff_2', 'temp_a_diff_2', 'temp_a_diff_1']\n",
    "X= aggr[features]\n",
    "y= aggr['target']\n",
    "X_sc = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "X_pca = pca.fit(X_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = PolynomialFeatures(degree = 1)\n",
    "X_new = pf.fit_transform(X)\n",
    "print(X_new.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new,\n",
    "                                                    y,\n",
    "                                                    random_state = 42,\n",
    "                                                    shuffle = False)\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set up GridsearchCV pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('pf', PolynomialFeatures()),\n",
    "                 ('scaler', StandardScaler()),\n",
    "                 ('pca', PCA()),\n",
    "                 ('ridge', Ridge())])\n",
    "pipe_params = { 'pf__degree' : [1,3],\n",
    "                'pca__n_components' : [2,3,5,6],\n",
    "                'ridge__alpha':[.0001,.5,1,3,5,9,13]}\n",
    "pipe_gridsearch = GridSearchCV(pipe,\n",
    "                                 pipe_params,\n",
    "                                 cv = 5,\n",
    "                                verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ss.fit_transform(X)\n",
    "pf = PolynomialFeatures(degree=1)\n",
    "X_new = pf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new,\n",
    "                                                    y,\n",
    "                                                    random_state = 52,\n",
    "                                                    shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 2, random_state = 42)\n",
    "pca.fit(X_train)\n",
    "Z_train = pca.transform(X_train)\n",
    "Z_test = pca.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = Ridge(alpha=8, fit_intercept=False,random_state=42, solver='auto')\n",
    "ridge_model.fit(Z_train, y_train)\n",
    "pred = ridge_model.predict(Z_test)\n",
    "print(ridge_model.score(Z_train, y_train))\n",
    "evaluate_model(ridge_model, Z_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot Predicted Temperature Anomaly vs Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = aggr.tail(12)\n",
    "check = pd.DataFrame(check['temp_anomaly'])\n",
    "hold = [None]*2\n",
    "hold.extend(list(pred))\n",
    "check['temp_a_diff_est'] = hold\n",
    "transf = [None]*12\n",
    "transf[2] = 0.62\n",
    "for i in range (3,12):\n",
    "    transf[i] = transf[i-1]+check.iloc[i-1,1]\n",
    "check['pred_temp_anomaly'] = transf\n",
    "check = check.iloc[3:]\n",
    "print(mean_squared_error(check['temp_anomaly'],check['pred_temp_anomaly']))\n",
    "ax3 = check.reset_index().plot(kind='scatter',x='index', y='temp_anomaly', color='r', figsize =(12,8))    \n",
    "ax4 = check.reset_index().plot(kind='scatter',x='index', y='pred_temp_anomaly', color='g', ax=ax3) \n",
    "ax3.legend(labels = ['Actual', 'Predicted'])\n",
    "ax3.set_title('Actual vs Predicted Temperature Anomalies in Celsius');\n",
    "ax3.set_xlabel('Year')\n",
    "ax3.set_ylabel('Temperature Anomaly (ºC)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_alphas = np.logspace(-3, 0, 100)\n",
    "lasso_cv = LassoCV(alphas=l_alphas, cv=5, max_iter=5000,random_state=42, fit_intercept=False)\n",
    "\n",
    "lasso_cv.fit(Z_train, y_train)\n",
    "pred = lasso_cv.predict(Z_test)\n",
    "evaluate_model(lasso_cv, Z_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot Predicted Temperature Anomaly vs Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = aggr.tail(12)\n",
    "check = pd.DataFrame(check['temp_anomaly'])\n",
    "hold = [None]*2\n",
    "hold.extend(list(pred))\n",
    "check['temp_a_diff_est'] = hold\n",
    "transf = [None]*12\n",
    "transf[2] = 0.62\n",
    "for i in range (3,12):\n",
    "    transf[i] = transf[i-1]+check.iloc[i-1,1]\n",
    "check['pred_temp_anomaly'] = transf\n",
    "check = check.iloc[3:]\n",
    "print(mean_squared_error(check['temp_anomaly'],check['pred_temp_anomaly']))\n",
    "ax3 = check.reset_index().plot(kind='scatter',x='index', y='temp_anomaly', color='r',figsize=(12,7))    \n",
    "ax4 = check.reset_index().plot(kind='scatter',x='index', y='pred_temp_anomaly', color='g', ax=ax3)\n",
    "ax3.legend(labels = ['Actual', 'Predicted'])\n",
    "ax3.set_title('Actual vs Predicted Temperature Anomalies in Celsius');\n",
    "ax3.set_xlabel('Year')\n",
    "ax3.set_ylabel('Temperature Anomaly (ºC)');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
